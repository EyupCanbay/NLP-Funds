{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kütüphanelerin import edilmesi\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from sklearn.decomposition import PCA # priciple componenet analysis\n",
    "# cok boyutlu vektörlere boyut indirgemesi yapıcağız \n",
    "# dimension reduction\n",
    "from gensim.models import Word2Vec, FastText\n",
    "from gensim.utils import simple_preprocess\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # 3D çizim için gerekli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# örnek veriseti oluşturma\n",
    "sentences = [\n",
    "    \"Köpek çok tatlı bir hayvandır\",\n",
    "    \"Köpekler evcil hayvanlardır\",\n",
    "    \"Kediler genellikle bağımsız haraket etmeyi severler\",\n",
    "    \"Köpekler sadık ve dost canlısı hayvanlardır\",\n",
    "    \"Hayvanlar insanlar için iyi arkadaşlardır\",\n",
    "]\n",
    "\n",
    "# küçük harflere cevirip tokenize yapmak için simple_process işlemi yaptık\n",
    "# farklı yollar var tabiki ben bunu kullandım bu sefer\n",
    "tokenizeSentences =[simple_preprocess(sentence) for sentence in sentences]\n",
    "print(tokenizeSentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec\n",
    "word2_vector_model = Word2Vec(sentences= tokenizeSentences, vector_size=50, window=5, min_count=1, sg=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fasttext\n",
    "fasttext_model = FastText(sentences= tokenizeSentences, vector_size=50, window=5, min_count=1, sg=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# görselleştirme tekniği PCA\n",
    "def plot_word_embedding(model, title):\n",
    "    word_vectors = model.wv \n",
    "    words = list(word_vectors.index_to_key)[:1000]\n",
    "    vectors = [word_vectors[word] for word in words]\n",
    "\n",
    "    #PCA \n",
    "    pca = PCA(n_components=4)\n",
    "    reduced_vectors = pca.fit_transform(vectors)\n",
    "\n",
    "    #3d görselleştirme\n",
    "    fig = plt.figure(figsize = (6,4))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    #vektorleri ciz\n",
    "    ax.scatter(reduced_vectors[:,0], reduced_vectors[:,1], reduced_vectors[:,2])\n",
    "\n",
    "    # kelimeleri etiketle\n",
    "    for i, word in enumerate(words):\n",
    "        ax.text(reduced_vectors[i,0],reduced_vectors[i,1], reduced_vectors[i,2], word , fontsize=5)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"component 1\")\n",
    "    ax.set_ylabel(\"component 2\")\n",
    "    ax.set_zlabel(\"component 3\")\n",
    "    plt.show()\n",
    "plot_word_embedding(word2_vector_model, \"Word2vector\")\n",
    "plot_word_embedding(fasttext_model, \"FastText\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
